{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:35.058771094Z",
     "start_time": "2023-12-24T16:32:33.441152016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 00:32:33.634727: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-25 00:32:33.636738: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-25 00:32:33.663556: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-25 00:32:33.663583: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-25 00:32:33.664327: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-25 00:32:33.668702: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-25 00:32:33.669073: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-25 00:32:34.247922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from modules import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load The Data\n",
    "The user content is composed of engineered features. A per genre average rating is computed per user. Additionally, a user id, rating count and rating average are available but not included in the training or prediction content. They are carried with the data set because they are useful in interpreting data.\n",
    "\n",
    "The training set consists of all the ratings made by the users in the data set. Some ratings are repeated to boost the number of training examples of underrepresented genre's. The training set is split into two arrays with the same number of entries, a user array and a destination/item array.\n",
    "\n",
    "Below, let's load and display some of the data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee2dca71e1ada6d8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: 437, user: 437, y:  437, item features: 9, user features: 9, item vectors: 437, destination dict: 437\n"
     ]
    }
   ],
   "source": [
    "item_train, user_train, y_train, item_features, user_features, item_vecs, destination_dict = load_data()\n",
    "num_user_features = user_train.shape[1] - 3 # remove remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1 # remove destination id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "\n",
    "print(f\"item: {len(item_train)}, user: {len(user_train)}, y:  {len(y_train)}, item features: {len(item_features)}, user features: {len(user_features)}, item vectors: {len(item_vecs)}, destination dict: {len(destination_dict)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:38.849655693Z",
     "start_time": "2023-12-24T16:32:38.825931061Z"
    }
   },
   "id": "1150528732dcb0b0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "            0                1                  2         3         4  \\\n0  [Use r_Id]  [Rating _Count]  [Rating_ Average]   Bah ari   Bud aya   \n1           1               30           3.366667       2.0       3.5   \n2           2               29           3.241379       2.0  3.444444   \n3           3               30           3.366667  4.333333  3.230769   \n4           4               26           3.423077       5.0  3.083333   \n5           5               33           3.363636       3.5  3.285714   \n\n            5                   6              7              8  \n0  Cagar Alam  Pusat Perbelanjaan  Taman Hiburan  Tempat Ibadah  \n1    3.444444                 3.0            3.8            2.0  \n2         2.8                 0.0            3.5            4.0  \n3         4.0                 0.0            2.9            5.0  \n4        3.75                 4.0            3.5            0.0  \n5    2.888889                 5.0       3.461538            5.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Use r_Id]</td>\n      <td>[Rating _Count]</td>\n      <td>[Rating_ Average]</td>\n      <td>Bah ari</td>\n      <td>Bud aya</td>\n      <td>Cagar Alam</td>\n      <td>Pusat Perbelanjaan</td>\n      <td>Taman Hiburan</td>\n      <td>Tempat Ibadah</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>30</td>\n      <td>3.366667</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>3.444444</td>\n      <td>3.0</td>\n      <td>3.8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>29</td>\n      <td>3.241379</td>\n      <td>2.0</td>\n      <td>3.444444</td>\n      <td>2.8</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>30</td>\n      <td>3.366667</td>\n      <td>4.333333</td>\n      <td>3.230769</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.9</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>26</td>\n      <td>3.423077</td>\n      <td>5.0</td>\n      <td>3.083333</td>\n      <td>3.75</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>33</td>\n      <td>3.363636</td>\n      <td>3.5</td>\n      <td>3.285714</td>\n      <td>2.888889</td>\n      <td>5.0</td>\n      <td>3.461538</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(user_train, user_features, uvs,  u_s, maxcount=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:41.141622654Z",
     "start_time": "2023-12-24T16:32:41.119350320Z"
    }
   },
   "id": "b7250e6e1db3f95e",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some of the user and item/destination features are not used in training. In the table above, the features in brackets \"[]\" such as the \"user id\", \"rating count\" and \"rating ave\" are not included when the model is trained and used."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "409f169e44d7078e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             0       1               2        3        4           5  \\\n0  [Plac e_Id]   Price  Place_ Ratings  Bah ari  Bud aya  Cagar Alam   \n1            1   20000        3.722222      0.0      1.0         0.0   \n2            2       0            2.84      0.0      1.0         0.0   \n3            3  270000        2.526316      0.0      0.0         0.0   \n4            4   10000        2.857143      0.0      0.0         0.0   \n5            5   94000            3.52      0.0      0.0         0.0   \n\n                    6              7              8  \n0  Pusat Perbelanjaan  Taman Hiburan  Tempat Ibadah  \n1                 0.0            0.0            0.0  \n2                 0.0            0.0            0.0  \n3                 0.0            1.0            0.0  \n4                 0.0            1.0            0.0  \n5                 0.0            1.0            0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Plac e_Id]</td>\n      <td>Price</td>\n      <td>Place_ Ratings</td>\n      <td>Bah ari</td>\n      <td>Bud aya</td>\n      <td>Cagar Alam</td>\n      <td>Pusat Perbelanjaan</td>\n      <td>Taman Hiburan</td>\n      <td>Tempat Ibadah</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>20000</td>\n      <td>3.722222</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2.84</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>270000</td>\n      <td>2.526316</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>10000</td>\n      <td>2.857143</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>94000</td>\n      <td>3.52</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(item_train, item_features, ivs,  i_s, maxcount=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:43.350127519Z",
     "start_time": "2023-12-24T16:32:43.336442919Z"
    }
   },
   "id": "b7504267535efed4",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preparing the training data\n",
    "Below, the inverse_transform is also shown to produce the original inputs. We'll scale the target ratings using a Min Max Scaler which scales the target to be between -1 and 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78055750460786e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "item_train_unscaled = item_train\n",
    "user_train_unscaled = user_train\n",
    "y_train_unscaled    = y_train\n",
    "\n",
    "scalerItem = StandardScaler()\n",
    "scalerItem.fit(item_train)\n",
    "item_train = scalerItem.transform(item_train)\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "scalerUser.fit(user_train)\n",
    "user_train = scalerUser.transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))\n",
    "scalerTarget.fit(y_train.reshape(-1, 1))\n",
    "y_train = scalerTarget.transform(y_train.reshape(-1, 1))\n",
    "\n",
    "print(np.allclose(item_train_unscaled, scalerItem.inverse_transform(item_train)))\n",
    "print(np.allclose(user_train_unscaled, scalerUser.inverse_transform(user_train)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:46.747186168Z",
     "start_time": "2023-12-24T16:32:46.708973164Z"
    }
   },
   "id": "61581d55a3301e17",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "To allow us to evaluate the results, we will split the data into training and test sets\n",
    "Here we will use sklean train_test_split to split and shuffle the data. Note that setting the initial random state to the same value ensures item, user, and y are shuffled identically"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbe21b5954c68e08"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destination/item training data shape: (349, 9)\n",
      "destination/item test data shape: (88, 9)\n"
     ]
    }
   ],
   "source": [
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"destination/item training data shape: {item_train.shape}\")\n",
    "print(f\"destination/item test data shape: {item_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:49.042611953Z",
     "start_time": "2023-12-24T16:32:48.999184336Z"
    }
   },
   "id": "884c6323074d93e2",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Neural Network for content-based filtering\n",
    "It will have two networks that are combined by a dot product. We construct the two networks. In this example, they will be identical. Note that these networks do not need to be the same. If the user content was substantially larger than the destination content, you might elect to increase the complexity of the user network relative to the destination network. In this case, the content is similar, so the networks are the same"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57d4f8e74514a5b5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 32)                   38816     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 32)                   39328     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOp  (None, 32)                   0         ['sequential[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_1 (TF  (None, 32)                   0         ['sequential_1[0][0]']        \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 1)                    0         ['tf.math.l2_normalize[0][0]',\n",
      "                                                                     'tf.math.l2_normalize_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78144 (305.25 KB)\n",
      "Trainable params: 78144 (305.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='linear'),\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='linear'),\n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=num_user_features)\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=num_item_features)\n",
    "vd = item_NN(input_item)\n",
    "vd = tf.linalg.l2_normalize(vd, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vd])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:51.817905336Z",
     "start_time": "2023-12-24T16:32:51.619097156Z"
    }
   },
   "id": "b11b7e6fc3c4ec31",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use a mean squared error loss and an Adam optimizer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfea36eb1a5114e6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss=cost_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:54.247008850Z",
     "start_time": "2023-12-24T16:32:54.223260241Z"
    }
   },
   "id": "b86a99d6cea99ec3",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.0892\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0314\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0131\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0086\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0070\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0052\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0033\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.9106e-04\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 7.8368e-04\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1450e-04\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 7.1017e-04\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.4393e-04\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.3373e-04\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1334e-04\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.7948e-04\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.3124e-04\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.4152e-04\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.6038e-04\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.5022e-04\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.7138e-04\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1167e-04\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.8523e-04\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9053e-04\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.1026e-04\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.0675e-04\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0136e-04\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.3286e-04\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.4188e-04\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.0034e-04\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.4508e-04\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.0224e-04\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.9288e-04\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0825e-04\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.7536e-04\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.2737e-04\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.7267e-04\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.0818e-04\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.0547e-04\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0119e-04\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1588e-04\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.2217e-04\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1213e-04\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.9832e-04\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1787e-04\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2700e-04\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8848e-04\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8858e-04\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4099e-04\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.2026e-04\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.8235e-04\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3558e-04\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.9253e-04\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.7735e-04\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.9938e-04\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.5721e-04\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.4327e-04\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7f541a3419f0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([user_train[:, u_s:], item_train[:, i_s:]], y_train, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:32:58.712174979Z",
     "start_time": "2023-12-24T16:32:54.983195836Z"
    }
   },
   "id": "e22491c7afd8a616",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.008993084542453289"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:33:00.179699511Z",
     "start_time": "2023-12-24T16:33:00.044642917Z"
    }
   },
   "id": "eb56f66de782de1f",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predictions\n",
    "Below, use the model to make predictions in a number of circumstances\n",
    "we'll create a user and have the model suggest destination for that user. After you have tried this on the example user content, feel free to change the user content to match your own preferences and see what the model suggests. Note that ratings are between 0.5 and 5.0, inclusive, in half-step increments."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e49111305f473835"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "new_id = 5000\n",
    "new_rating_count = 20.0\n",
    "new_rating_ave = 10.0\n",
    "new_bahari = 0.0\n",
    "new_budaya = 5.0\n",
    "new_cagar_alam = 5.0\n",
    "new_pusat_perbelanjaan = 5.0\n",
    "new_taman_hiburan = 0.0\n",
    "new_tempat_ibadah = 0.0\n",
    "\n",
    "user_vec = np.array([[new_id, new_rating_count, new_rating_ave,\n",
    "                      new_bahari, new_budaya, new_cagar_alam, new_pusat_perbelanjaan,\n",
    "                      new_taman_hiburan, new_tempat_ibadah]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:33:02.656071058Z",
     "start_time": "2023-12-24T16:33:02.625364766Z"
    }
   },
   "id": "44ab79b1079230cd",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "       0    1           2                                                  3  \\\n0    y_p   id  rating ave                                               name   \n1    3.0  179         3.1                                    Candi Ratu Boko   \n2    3.0  325         2.9                           Saung Angklung Mang Udjo   \n3    3.0   39         3.3  Museum Macan (Modern and Contemporary Art in N...   \n4    3.0  331         2.8                            Kyotoku Floating Market   \n..   ...  ...         ...                                                ...   \n96   3.0   43         2.6                                    The Escape Hunt   \n97   3.0   35         3.0                               Grand Indonesia Mall   \n98   3.0    3         2.5                                      Dunia Fantasi   \n99   3.0   45         2.7                        Jakarta Aquarium dan Safari   \n100  3.0   75         2.8                                  SnowBay Waterpark   \n\n                      4  \n0              category  \n1                Budaya  \n2                Budaya  \n3                Budaya  \n4                Budaya  \n..                  ...  \n96        Taman Hiburan  \n97   Pusat Perbelanjaan  \n98        Taman Hiburan  \n99        Taman Hiburan  \n100       Taman Hiburan  \n\n[101 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>y_p</td>\n      <td>id</td>\n      <td>rating ave</td>\n      <td>name</td>\n      <td>category</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>179</td>\n      <td>3.1</td>\n      <td>Candi Ratu Boko</td>\n      <td>Budaya</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>325</td>\n      <td>2.9</td>\n      <td>Saung Angklung Mang Udjo</td>\n      <td>Budaya</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>39</td>\n      <td>3.3</td>\n      <td>Museum Macan (Modern and Contemporary Art in N...</td>\n      <td>Budaya</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>331</td>\n      <td>2.8</td>\n      <td>Kyotoku Floating Market</td>\n      <td>Budaya</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>3.0</td>\n      <td>43</td>\n      <td>2.6</td>\n      <td>The Escape Hunt</td>\n      <td>Taman Hiburan</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>3.0</td>\n      <td>35</td>\n      <td>3.0</td>\n      <td>Grand Indonesia Mall</td>\n      <td>Pusat Perbelanjaan</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>3.0</td>\n      <td>3</td>\n      <td>2.5</td>\n      <td>Dunia Fantasi</td>\n      <td>Taman Hiburan</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>3.0</td>\n      <td>45</td>\n      <td>2.7</td>\n      <td>Jakarta Aquarium dan Safari</td>\n      <td>Taman Hiburan</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>3.0</td>\n      <td>75</td>\n      <td>2.8</td>\n      <td>SnowBay Waterpark</td>\n      <td>Taman Hiburan</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate and replicate the user vector to match the number destination in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "\n",
    "print_pred_destination(sorted_ypu, sorted_items, destination_dict, maxcount = 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:33:03.793738984Z",
     "start_time": "2023-12-24T16:33:03.618795180Z"
    }
   },
   "id": "8dda10c313c26f3b",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bf7f33a283bf6e1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
