{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:31:13.831508Z",
     "start_time": "2023-12-11T16:31:13.806048300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from urllib import request\n",
    "import os\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    data_dir = \"data\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    url_content_destination_list = \"https://raw.githubusercontent.com/Touventure/models/main/content-based-filtering/content_destinations_list.csv\"\n",
    "    url_content_item_train = \"https://raw.githubusercontent.com/Touventure/models/main/content-based-filtering/content_item_train.csv\"\n",
    "    url_content_item_train_header = \"https://raw.githubusercontent.com/Touventure/models/main/content-based-filtering/content_item_train_header.txt\"\n",
    "    url_content_item_vecs = \"https://raw.githubusercontent.com/Touventure/models/main/content-based-filtering/content_item_vecs.csv\"\n",
    "    url_content_user_train = \"https://raw.githubusercontent.com/Touventure/models/main/content-based-filtering/content_user_train.csv\"\n",
    "    url_content_user_train_header = \"https://raw.githubusercontent.com/Touventure/models/main/content-based-filtering/content_user_train_header.txt\"\n",
    "    url_content_y_train = \"https://raw.githubusercontent.com/Touventure/models/main/content-based-filtering/content_y_train.csv\"\n",
    "    \n",
    "    request.urlretrieve(url_content_destination_list, \"data/content_destination_list.csv\")\n",
    "    request.urlretrieve(url_content_item_train, \"data/content_item_train.csv\")\n",
    "    request.urlretrieve(url_content_item_train_header, \"data/content_item_train_header.txt\")\n",
    "    request.urlretrieve(url_content_item_vecs, \"data/content_item_vecs.csv\")\n",
    "    request.urlretrieve(url_content_user_train, \"data/content_user_train.csv\")\n",
    "    request.urlretrieve(url_content_user_train_header, \"data/content_user_train_header.txt\")\n",
    "    request.urlretrieve(url_content_y_train, \"data/content_y_train.csv\")\n",
    "\n",
    "    item_train = genfromtxt('data/content_item_train.csv', delimiter=',')\n",
    "    user_train = genfromtxt('data/content_user_train.csv', delimiter=',')\n",
    "    y_train    = genfromtxt('data/content_y_train.csv', delimiter=',')\n",
    "    with open('data/content_item_train_header.txt', newline='') as f:\n",
    "        item_features = list(csv.reader(f))[0]\n",
    "    with open('data/content_user_train_header.txt', newline='') as f:\n",
    "        user_features = list(csv.reader(f))[0]\n",
    "    item_vecs = genfromtxt('data/content_item_vecs.csv', delimiter=',')\n",
    "\n",
    "    destination_dict = defaultdict(dict)\n",
    "    count = 0\n",
    "\n",
    "    with open('data/content_destination_list.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for line in reader:\n",
    "            if count == 0:\n",
    "                count += 1\n",
    "            else:\n",
    "                count += 1\n",
    "                destination_id = int(line[0])\n",
    "                destination_dict[destination_id][\"name\"] = line[1]\n",
    "                destination_dict[destination_id][\"category\"] = line[2]\n",
    "\n",
    "    return item_train, user_train, y_train, item_features, user_features, item_vecs, destination_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:22:35.304701500Z",
     "start_time": "2023-12-11T16:22:35.279826800Z"
    }
   },
   "id": "b28c0c6ed3a2ef5e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def split_str(ifeatures, smax):\n",
    "    # split the feature name strings to tables fit\n",
    "    ofeatures = []\n",
    "    for s in ifeatures:\n",
    "        if not ' ' in s:  # skip string that already have a space\n",
    "            if len(s) > smax:\n",
    "                mid = int(len(s)/2)\n",
    "                s = s[:mid] + \" \" + s[mid:]\n",
    "        ofeatures.append(s)\n",
    "    return ofeatures"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:30:31.614895100Z",
     "start_time": "2023-12-11T16:30:31.601996Z"
    }
   },
   "id": "1de42550e21b705e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def pprint_train(x_train, features, vs, u_s, maxcount=5, user=True):\n",
    "    \"\"\" Prints user_train or item_train nicely \"\"\"\n",
    "    if user:\n",
    "        flist = [\".0f\", \".0f\", \".1f\",\n",
    "                 \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\"]\n",
    "    else:\n",
    "        flist = [\".0f\", \".0f\", \".1f\",\n",
    "                 \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\", \".0f\"]\n",
    "\n",
    "    head = features[:vs]\n",
    "    if vs < u_s: print(\"error, vector start {vs} should be greater then user start {u_s}\")\n",
    "    for i in range(u_s):\n",
    "        head[i] = \"[\" + head[i] + \"]\"\n",
    "    genres = features[vs:]\n",
    "    hdr = head + genres\n",
    "    disp = [split_str(hdr, 5)]\n",
    "    count = 0\n",
    "    for i in range(0, x_train.shape[0]):\n",
    "        if count == maxcount: break\n",
    "        count += 1\n",
    "        disp.append([x_train[i, 0].astype(int),\n",
    "                     x_train[i, 1].astype(int),\n",
    "                     x_train[i, 2].astype(float),\n",
    "                     *x_train[i, 3:].astype(float)\n",
    "                     ])\n",
    "    table = tabulate.tabulate(disp, tablefmt='html', headers=\"firstrow\", floatfmt=flist, numalign='center')\n",
    "    return pd.DataFrame(disp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:35:57.761436100Z",
     "start_time": "2023-12-11T16:35:57.748222900Z"
    }
   },
   "id": "be1a4d6acbe44c60"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def gen_user_vecs(user_vec, num_items):\n",
    "    user_vecs = np.tile(user_vec, (num_items, 1))\n",
    "    return user_vecs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:53:46.767925300Z",
     "start_time": "2023-12-11T16:53:46.748423900Z"
    }
   },
   "id": "c8f4ef9f5217be12"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "\n",
    "def print_pred_destinations(y_p, item, destination_dict, maxcount=10):\n",
    "    count = 0\n",
    "    disp = [[\"y_p\", \"place id\", \"rating ave\", \"name\", \"category\"]]\n",
    "\n",
    "    for i in range(0, y_p.shape[0]):\n",
    "        if count == maxcount:\n",
    "            break\n",
    "        count += 1\n",
    "        destination_id = item[i, 0].astype(int)\n",
    "        disp.append([np.around(y_p[i, 0], 1), item[i, 0].astype(int), np.around(item[i, 2].astype(float), 1),\n",
    "                     destination_dict[destination_id]['name'], destination_dict[destination_id]['category']])\n",
    "\n",
    "    # table = tabulate.tabulate(disp, tablefmt='html', headers=\"firstrow\")\n",
    "    return pd.DataFrame(disp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:58:34.633899900Z",
     "start_time": "2023-12-11T16:58:34.612052800Z"
    }
   },
   "id": "4d60ac51c2e034c1"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training vectors: 437\n"
     ]
    }
   ],
   "source": [
    "item_train, user_train, y_train, item_features, user_features, item_vecs, destination_dict = load_data()\n",
    "\n",
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove place id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "print(f\"Number of training vectors: {len(item_train)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:36:04.398510800Z",
     "start_time": "2023-12-11T16:36:01.071553900Z"
    }
   },
   "id": "eb2106a2474f658a"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[:5]: [3.36666667 3.24137931 3.36666667 3.42307692 3.36363636]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train[:5]: {y_train[:5]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:41:07.214806900Z",
     "start_time": "2023-12-11T16:41:07.184881300Z"
    }
   },
   "id": "ace84d0e705cd609"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "item_train_unscaled = item_train\n",
    "user_train_unscaled = user_train\n",
    "y_train_unscaled    = y_train\n",
    "\n",
    "scalerItem = StandardScaler()\n",
    "scalerItem.fit(item_train)\n",
    "item_train = scalerItem.transform(item_train)\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "scalerUser.fit(user_train)\n",
    "user_train = scalerUser.transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))\n",
    "scalerTarget.fit(y_train.reshape(-1, 1))\n",
    "y_train = scalerTarget.transform(y_train.reshape(-1, 1))\n",
    "#ynorm_test = scalerTarget.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(np.allclose(item_train_unscaled, scalerItem.inverse_transform(item_train)))\n",
    "print(np.allclose(user_train_unscaled, scalerUser.inverse_transform(user_train)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:42:50.013459600Z",
     "start_time": "2023-12-11T16:42:49.957148400Z"
    }
   },
   "id": "a8a2a01478209fe3"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destination/item training data shape: (279, 9)\n",
      "destination/item test data shape: (70, 9)\n"
     ]
    }
   ],
   "source": [
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"destination/item training data shape: {item_train.shape}\")\n",
    "print(f\"destination/item test data shape: {item_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:44:13.084887Z",
     "start_time": "2023-12-11T16:44:13.061982200Z"
    }
   },
   "id": "82d5e921335e50d8"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 32)                   38816     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 32)                   39328     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOp  (None, 32)                   0         ['sequential[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_1 (TF  (None, 32)                   0         ['sequential_1[0][0]']        \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 1)                    0         ['tf.math.l2_normalize[0][0]',\n",
      "                                                                     'tf.math.l2_normalize_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78144 (305.25 KB)\n",
      "Trainable params: 78144 (305.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='linear'),\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='linear'),\n",
    "])\n",
    "\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:45:13.514242600Z",
     "start_time": "2023-12-11T16:45:12.725397800Z"
    }
   },
   "id": "4444742cf71814f"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:47:27.611773Z",
     "start_time": "2023-12-11T16:47:27.563901700Z"
    }
   },
   "id": "e0d5b9003043ef35"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.6446e-04\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.7401e-04\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.0751e-04\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.2922e-04\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.0015e-04\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.8721e-04\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.0924e-04\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 3.2206e-04\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.3806e-04\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.2794e-04\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.3961e-04\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.7225e-04\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.9584e-04\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.2514e-04\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.4698e-04\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.5947e-04\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.9388e-04\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.5986e-04\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.0901e-04\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.4256e-04\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.2307e-04\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.3388e-04\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.6447e-04\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.6638e-04\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.8314e-04\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.0640e-04\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.4964e-04\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.3063e-04\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.7269e-04\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.7477e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x237f840d0f0>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([user_train[:, u_s:], item_train[:, i_s:]], y_train, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:10:04.291485Z",
     "start_time": "2023-12-11T17:10:03.130389900Z"
    }
   },
   "id": "d94b1db63023e490"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0128\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.012821502983570099"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T16:49:40.046062100Z",
     "start_time": "2023-12-11T16:49:39.736580200Z"
    }
   },
   "id": "a352ec409e3de826"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "new_user_id = 501\n",
    "new_rating_ave = 0.0\n",
    "new_Bahari = 15.0\n",
    "new_Budaya = 10.0\n",
    "new_Cagar_Alam = 10.0\n",
    "new_Pusat_Perbelanjaan = 10.0\n",
    "new_Taman_Hiburan = 10.0\n",
    "new_Tempat_Ibadah = 2.0\n",
    "new_rating_count = 0\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave, new_Bahari, new_Budaya, new_Cagar_Alam, new_Pusat_Perbelanjaan, new_Taman_Hiburan, new_Tempat_Ibadah]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:15:15.010122Z",
     "start_time": "2023-12-11T17:15:14.990599800Z"
    }
   },
   "id": "2885ac847ea40e8d"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "      0         1           2                                  3           4\n0   y_p  place id  rating ave                               name    category\n1   3.9       141         3.2             Bunker Kaliadem Merapi  Cagar Alam\n2   3.9       379         3.2                           Goa Rong  Cagar Alam\n3   3.9       357         3.2  Wisata Alam Wana Wisata Penggaron  Cagar Alam\n4   3.9       256         3.2                   Wisata Batu Kuda  Cagar Alam\n5   3.9       319         3.2             Kawah Rengganis Cibuni  Cagar Alam\n6   3.9       217         3.2             Kebun Binatang Bandung  Cagar Alam\n7   3.9       211         3.2             GunungTangkuban perahu  Cagar Alam\n8   3.9       312         3.2     Taman Hutan Raya Ir. H. Juanda  Cagar Alam\n9   3.9       242         3.2                         Curug Dago  Cagar Alam\n10  3.9       367         3.3                Wisata Lereng Kelir  Cagar Alam",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>y_p</td>\n      <td>place id</td>\n      <td>rating ave</td>\n      <td>name</td>\n      <td>category</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.9</td>\n      <td>141</td>\n      <td>3.2</td>\n      <td>Bunker Kaliadem Merapi</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.9</td>\n      <td>379</td>\n      <td>3.2</td>\n      <td>Goa Rong</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.9</td>\n      <td>357</td>\n      <td>3.2</td>\n      <td>Wisata Alam Wana Wisata Penggaron</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.9</td>\n      <td>256</td>\n      <td>3.2</td>\n      <td>Wisata Batu Kuda</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.9</td>\n      <td>319</td>\n      <td>3.2</td>\n      <td>Kawah Rengganis Cibuni</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.9</td>\n      <td>217</td>\n      <td>3.2</td>\n      <td>Kebun Binatang Bandung</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3.9</td>\n      <td>211</td>\n      <td>3.2</td>\n      <td>GunungTangkuban perahu</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.9</td>\n      <td>312</td>\n      <td>3.2</td>\n      <td>Taman Hutan Raya Ir. H. Juanda</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.9</td>\n      <td>242</td>\n      <td>3.2</td>\n      <td>Curug Dago</td>\n      <td>Cagar Alam</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3.9</td>\n      <td>367</td>\n      <td>3.3</td>\n      <td>Wisata Lereng Kelir</td>\n      <td>Cagar Alam</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]\n",
    "print_pred_destinations(sorted_ypu, sorted_items, destination_dict, maxcount = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:15:21.948978300Z",
     "start_time": "2023-12-11T17:15:21.805321500Z"
    }
   },
   "id": "709a525a57fa727"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "70851633234592c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
